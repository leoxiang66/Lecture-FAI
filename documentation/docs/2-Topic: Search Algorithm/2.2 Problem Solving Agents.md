# Problem Solving Agents
一个agent需要最大化他的performance measure. 如果给这个agent设计一个(好的)goal, 这会最大化performance measure变得容易。

**Problem Solving 第一步： Goal Formulation**

- based on the current situation and
- the agent's performance

通常， goals are defined as a *set of world states*

> example goal: be in city Munich

**Problem Solving 第二步： Problem Formulation**

在确定goal以后， 我们需要定义可用的actions和states. 

Problem formulation is the process of deciding what actions and states to consider, given a goal.

> actions: go from one city to other
> states: be in a certain city

> Our agent has now adopted the goal of driving to Bucharest and is considering where to go from Arad. Three roads lead out of Arad, one toward Sibiu, one to Timisoara, and one to Zerind. None of these achieves the goal, so unless the agent is familiar with the geography of Romania, it will not know which road to follow. ${ }^1$ In other words, the agent will not know which of its possible actions is best, because it does not yet know enough about the state that results from taking each action. If the agent has no additional information-i.e., if the environment is **unknown** in the sense defined in Section 2.3-then it is has no choice but to try one of the actions at random. This sad situation is discussed in Chapter 4 .

Assumptions:

1. the environment is known: agent knows which states are reached by each action
2. the environment is observable 代理可以知道它当前的state
3. the environment is discrete: at any given state there are only finitely many actions to choose from
4. the environment is deterministic: 某个action都有一个确定的结果


**Problem Solving 第三步: Search**

solution to problems: 

- a fixed sequence of actions
- in general it could be a branching strategy that recommends different actions in the future depending on what percepts arrive (IF/ELSE)

Search: The process of looking for a sequence of actions that reaches the goal is called *search*.

- A search algorithm takes a problem as input and returns a solution in the form of an action sequence. 


**Problem Solving 第四步: Execution**

Once a solution is found, the actions it recommends can be carried out. This is called the *execution* phase. 

Thus, we have a simple "formulate, search, execute" design for the agent, as shown in Figure 3.1. 

- After formulating a goal and a problem to solve, the agent calls a search procedure to solve it. It then uses the solution to guide its actions, doing whatever the solution recommends as the next thing to do-typically, the first action of the sequence-and then removing that step from the sequence. 
- Once the solution has been executed, the agent will formulate a new goal.



> **Open-Loop:** execution过程中不看percepts. Notice that while the agent is executing the solution sequence it ignores its percepts when choosing an action because it knows in advance what they will be. An agent that carries out its plans with its eyes closed, so to speak, must be quite certain of what is going on. Control theorists call this an open-loop system, because ignoring the percepts breaks the loop between agent and environment.


## Well-defined problems and solutions
A **problem** can be defined formally by five components:

1. The **initial state** that the agent starts in
2. A description of the possible **actions** available to the agent. Given a particular state $s$, ACTIONS $(s)$ returns the set of actions that can be executed in $s$. We say that each of these actions is **applicable** in $s$. 
3. A description of what each action does; the formal name for this is the **transition model**, specified by a function $\operatorname{ResulT}(s, a)$ that returns the state that results from doing action $a$ in state $s$. We also use the term successor to refer to any state reachable from a given state by a single action. ${ }^2$ For example, we have ![](https://i.imgur.com/JzQhSWM.png)
> Together, the initial state, actions, and transition model implicitly define the state space of the problem-the set of all states reachable from the initial state by any sequence of actions. The state space forms a directed network or graph in which the nodes are states and the links between nodes are actions. A **path** in the state space is a sequence of states connected by a sequence of actions.
4. The **goal test**, which determines whether a given state is a goal state. Sometimes there is an explicit set of possible goal states, and the test simply checks whether the given state is one of them. 
5. A **path cost** function that assigns a numeric cost to each path. The problem-solving agent chooses a cost function that reflects its own performance measure. In this chapter, we assume that the cost of a path can be described as the sum of the costs of the individual actions along the path. ${ }^3$ The step cost of taking action $a$ in state $s$ to reach state $s^{\prime}$ is denoted by $c\left(s, a, s^{\prime}\right)$.  We assume that step costs are nonnegative. ${ }^4$


A **solution** to a problem is an action sequence that leads from the initial state to a goal state. Solution quality is measured by the path cost function, and an **optimal solution** has the lowest path cost among all solutions.

## Formulating Problems

**abstraction.** The process of removing detail from a representation. 现实中的环境状态包含太多信息， 但是很多信息都是与这个problem无关的。 删除无关信息 => abstraction.

除了抽象状态描述之外，我们还必须抽象动作本身。

Abstraction is 

- *valid* if we can expand any abstract solution into a solution in the more detailed world; a sufficient condition is that for every detailed state that is "in Arad," there is a detailed path to some state that is "in Sibiu," and so on.
-  *useful* if carrying out each of the actions in the solution is easier than the original problem; in this case they are easy enough that they can be carried out without further search or planning by an average driving agent.


The choice of a good abstraction thus involves removing as much detail as possible while retaining validity and ensuring that the abstract actions are easy to carry out. Were it not for the ability to construct useful abstractions, intelligent agents would be completely swamped by the real world.


## Searching for Solutions
A solution is an action sequence, so search algorithms work by considering various possible action sequences. 

The possible action sequences starting at the initial state form a **search tree** with the initial state at the root; the branches are actions and the **nodes** correspond to states in the state space of the problem. 

The root node of the tree corresponds to the initial state. The first step is to test whether this is a goal state.

Then we need to consider taking various actions. We do this by **expanding** the current state; that is, applying each legal action to the current state, thereby generating a new set of states. 

- In this case, we add three branches from the parent node $\operatorname{In}($ Arad) leading to three new child nodes: In(Sibiu), In (Timisoara), and $\operatorname{In}$ (Zerind). Now we must choose which of these three possibilities to consider further.

The set of all leaf nodes available for expansion at any given point is called the **frontier**

The eagle-eyed reader will notice one peculiar thing about the search tree shown in Figure 3.6: it includes the path from Arad to Sibiu and back to Arad again! We say that In(Arad)is a **repeated** state in the search tree, generated in this case by a **loopy path**.

## Measure Problem Solving
We can evaluate the performance of a search algorithm using the following criteria:

- Completeness: Is it guaranteed that the algorithm finds a solution if one exists?
- Optimality: Does the strategy find the optimal solution (minimum costs)?
- Time complexity: How long does it take to find a solution?
- Space complexity: How much memory is needed to perform the search?


## Infrastructure of Search Algorithms
![](https://i.imgur.com/7k6oybs.png)


